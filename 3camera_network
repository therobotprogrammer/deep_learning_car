
from keras.models import Model
from keras.layers import Input,Dense, Lambda, concatenate, SeparableConv1D, MaxPooling1D, Dropout, Conv2D, Flatten
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot
from keras.utils import plot_model
from sklearn.model_selection import train_test_split #to split out training and testing data 
from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, TensorBoard
from keras.optimizers import Adam

import os


import sys


utils_dir = '/home/pt/repository/deep_learning_car/utils'
sys.path.insert(0, utils_dir)
import custom_utils as custom_utils
from MultiSensorTimeSeriesGenerator import MultiSensorTimeSeriesGenerator


def show_sample_from_generator(generator, batch_generator_params):
    generator = train_generator
    iterator = generator.__iter__()
    batch = next(iterator)
    custom_utils.show_batch(batch, batch_generator_params, figsize=(15, 3))


#Q Why this notmalisation
def image_normalization(x):
    return ( (x/127.5) - 1.0 )
    
#To Do: Verify if Lambda is correctly used
def build_single_sensor_network(sensor_input):    
    x = Lambda(image_normalization)(sensor_input)
    #x = Dense(32)(x)
    return x

def show_model(model):
    display(SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')))



def build_nvidia_paper_model(sensor_count, single_sensor_input_shape):
    
    sensor_inputs = []
    sensor_outputs = []
    
    
    for sensor_id in range(0, sensor_count):
        #Q Will it if we make input_sensor = Input() and then appent list.append(input_sensor) 3 times. will it be same data or different for eact sensor?
        #Q How to do this as an array?
        
        single_sensor_input = Input(shape=single_sensor_input_shape)
        single_sensor_output = build_single_sensor_network(single_sensor_input)
        
        sensor_inputs.append(single_sensor_input)        
        sensor_outputs.append(single_sensor_output)
        

    x = concatenate(sensor_outputs)
    x = Conv2D(24, (5,5), strides=(2,2), activation='elu')(x)
    x = Conv2D(36, (5,5), strides=(2,2), activation='elu')(x)
    x = Conv2D(48, (5,5), strides=(2,2), activation='elu')(x)
    x = Conv2D(64, (3,3), strides=(1,1), activation='elu')(x)
    x = Conv2D(64, (3,3), strides=(1,1), activation='elu')(x)
    x = Dropout(.5)(x)
    x = Flatten()(x)
    x = Dense(100, activation = 'elu')(x)
    x = Dense(50, activation = 'elu')(x)
    x = Dense(10, activation = 'elu')(x)
    x = Dense(1, activation = 'elu')(x)
    
    
    #x = SeparableConv1D(5,1)(x)



    model = Model(inputs = sensor_inputs, outputs = x)
    model.summary()       
    return model
    


def get_sensor_count_and_input_shape(sample_generator):
    iterator = sample_generator.__iter__()    
      
    batch = next(iterator)
    input_data = batch[0]   
    
    sensor_count = len(input_data)    
    single_sensor_input_shape = input_data[0][0].shape
    
    return sensor_count, single_sensor_input_shape
    

######################################################################
from model_load_and_save import model_load_and_save

google_drive = '/home/pt/Desktop/temp'
model_save_top_directory = google_drive + '/deep_learning/01_Self_Driving_Car_Nvidia_Paper/saved_models' 
model_save_top_directory = '/home/pt/Desktop/saved_models/' 


save_load_params = {
                            'continue_training_last_model' : True,
                            'create_time_stamped_dirs' : True                                
                   }

model_saver = model_load_and_save(model_save_top_directory, **save_load_params)

###########################


model_params = {
            'train_to_test_split_ratio' : .8,
            'random_seed' : 0,
            'learning_rate': 1.0e-4
        }

batch_generator_params = {
             'length' : 1,
             'sampling_rate':1,
             'stride':1,
             'start_index':0,
             'end_index':None,
             'shuffle':False,
             'reverse':False,
             'batch_size':5,
             'image_dimention' : (160,320),
             'n_channels' : 3,
             'time_axis':False
         }



data_dir = '/home/pt/Desktop/debug_data'
driving_log_csv = data_dir + '/' + 'driving_log.csv'
driving_log = custom_utils.update_driving_log(data_dir, driving_log_csv)

split_point = int(len(driving_log) * model_params['train_to_test_split_ratio'])
driving_log_train = driving_log[0:split_point]
driving_log_validation = driving_log[split_point + batch_generator_params['length'] * 2:] # length*2 so that car has moved far away from train data spot

#if we done reset index, then test data has index split_point onwards. This will cause problem with timeseriesgenerator
driving_log_train = driving_log_train.reset_index()
driving_log_validation = driving_log_validation.reset_index() 


train_generator = MultiSensorTimeSeriesGenerator([driving_log_train['center'], driving_log_train['left'], driving_log_train['right']], driving_log_train['steering'], **batch_generator_params)
validation_generator = MultiSensorTimeSeriesGenerator([driving_log_validation['center'], driving_log_validation['left'], driving_log_validation['right']], driving_log_validation['steering'], **batch_generator_params)

show_sample_from_generator(train_generator, batch_generator_params)

sensor_count, input_shape = get_sensor_count_and_input_shape(train_generator)


if model_saver.continue_training_last_model and model_saver.model_loaded_sucessfully:
    model = model_saver.model
else:
    model = build_nvidia_paper_model(sensor_count, input_shape)

#show_model(model) 


#callbacks
save_weights = ModelCheckpoint(filepath=model_saver.model_save_file, monitor='val_loss', verbose =0, save_best_only=True, mode='auto')
csv_logger = CSVLogger(model_saver.csv_save_file)
tensorboard = TensorBoard(log_dir=model_saver.tensorboard_log_dir, histogram_freq=0, write_graph=True, write_images=True)
callbacks = [save_weights, csv_logger, tensorboard]




save_weights = ModelCheckpoint(model_saver.model_save_file, monitor='val_loss', save_best_only=True, mode='auto')

model.compile(optimizer= Adam(lr=model_params['learning_rate']), loss='mean_squared_error')

model.fit_generator(generator=train_generator, validation_data = validation_generator, use_multiprocessing = True, workers=4 )

#model.fit_generator(generator=train_generator, validation_data = validation_generator)
























